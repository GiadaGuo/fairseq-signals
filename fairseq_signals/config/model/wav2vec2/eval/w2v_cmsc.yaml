common:
  fp16: false
  log_format: json
  log_interval: 50
  all_gather_list_size: 2048000

common_eval:
  path: ???

task:
  _name: ecg_pretraining
  clocs_mode: cmsc
  data: ???
  normalize: false
  enable_padding: true
  enable_padding_leads: false
  leads_to_load: null
    # I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6

dataset:
  num_workers: 6
  max_tokens: null
  batch_size: 64
  valid_subset: "train"

distributed_training:
  distributed_world_size: 1

criterion:
  _name: wav2vec2_with_clocs
  infonce: true
  log_keys: ["prob_perplexity", "code_perplexity", "temp"]
  loss_weights: [0.1, 10]

model:
  _name: wav2vec2_clocs
  quantize_targets: true
  final_dim: 256
  encoder_layerdrop: 0.05
  dropout_input: 0.1
  dropout_features: 0.1
  feature_grad_mult: 0.1
  encoder_embed_dim: 768
  in_d: 12